{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GAN tensorflow 2.0 实现\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成器网络：将输入的 100 维的向量转换为 28x28x1 的图像\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(256, input_shape=(100,), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(784, activation='tanh'),  # 输出图像大小为 28x28\n",
    "        layers.Reshape((28, 28, 1))  # 转换形状为图像\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 判别器网络：将输入的 28x28x1 的图像转换为一个二分类结果\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # 输出一个判别结果，0表示伪造图像，1表示真实图像\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# GAN 模型\n",
    "def build_gan(generator, discriminator):\n",
    "    # discriminator.trainable = False  # 冻结判别器的权重，只训练生成器\n",
    "    discriminator.trainable = True  # 冻结判别器的权重，只训练生成器\n",
    "    model = tf.keras.Sequential([generator, discriminator])\n",
    "    return model\n",
    "\n",
    "# 生成并保存生成器生成的图像。\n",
    "def generate_and_save_images(generator, epoch, examples=10):\n",
    "    noise = np.random.normal(0, 1, (examples, 100))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5  # 将图像归一化到[0, 1]范围\n",
    "    \n",
    "    plt.figure(figsize=(10, 1))\n",
    "    for i in range(examples):\n",
    "        plt.subplot(1, examples, i + 1)\n",
    "        plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # 归一化到[-1, 1]范围\n",
    "\n",
    "# 创建生成器、判别器和 GAN 模型\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "\n",
    "\n",
    "# 训练 GAN 模型\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(train_images.shape[0] // batch_size):\n",
    "        # 随机选择一批真实图像\n",
    "        real_images = train_images[np.random.randint(0, train_images.shape[0], batch_size)]\n",
    "        \n",
    "        # 生成随机噪声作为输入\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        \n",
    "        # 使用生成器生成假图像\n",
    "        generated_images = generator.predict(noise)\n",
    "        \n",
    "        # 训练判别器\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            real_logits = discriminator(real_images)\n",
    "            fake_logits = discriminator(generated_images)\n",
    "            \n",
    "            real_loss = cross_entropy(real_labels, real_logits)\n",
    "            fake_loss = cross_entropy(fake_labels, fake_logits)\n",
    "            total_discriminator_loss = real_loss + fake_loss\n",
    "        \n",
    "        gradients_discriminator = disc_tape.gradient(total_discriminator_loss, discriminator.trainable_variables)\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_discriminator, discriminator.trainable_variables))\n",
    "        \n",
    "        # 训练生成器\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            generated_images = generator(noise)\n",
    "            fake_logits = discriminator(generated_images)\n",
    "            generator_loss = cross_entropy(real_labels, fake_logits)\n",
    "        \n",
    "        gradients_generator = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(gradients_generator, generator.trainable_variables))\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Generator Loss: {generator_loss}, Discriminator Loss: {total_discriminator_loss}')\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        generate_and_save_images(generator, epoch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成器网络：将输入的 100 维的向量转换为 28x28x1 的图像\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(256, input_shape=(100,), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(784, activation='tanh'),  # 输出图像大小为 28x28\n",
    "        layers.Reshape((28, 28, 1))  # 转换形状为图像\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 判别器网络：将输入的 28x28x1 的图像转换为一个二分类结果\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # 输出一个判别结果，0表示伪造图像，1表示真实图像\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# GAN 模型\n",
    "def build_gan(generator, discriminator):\n",
    "    # discriminator.trainable = False  # 冻结判别器的权重，只训练生成器\n",
    "    discriminator.trainable = True  # 冻结判别器的权重，只训练生成器\n",
    "    model = tf.keras.Sequential([generator, discriminator])\n",
    "    return model\n",
    "\n",
    "# 生成并保存生成器生成的图像。\n",
    "def generate_and_save_images(generator, epoch, examples=10):\n",
    "    noise = np.random.normal(0, 1, (examples, 100))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5  # 将图像归一化到[0, 1]范围\n",
    "    \n",
    "    plt.figure(figsize=(10, 1))\n",
    "    for i in range(examples):\n",
    "        plt.subplot(1, examples, i + 1)\n",
    "        plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 MNIST 数据集\n",
    "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # 归一化到[-1, 1]范围\n",
    "\n",
    "# 创建生成器、判别器和 GAN 模型\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练 GAN 模型\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(train_images.shape[0] // batch_size):\n",
    "        # 随机选择一批真实图像\n",
    "        real_images = train_images[np.random.randint(0, train_images.shape[0], batch_size)]\n",
    "        \n",
    "        # 生成随机噪声作为输入\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        \n",
    "        # 使用生成器生成假图像\n",
    "        generated_images = generator.predict(noise)\n",
    "        \n",
    "        # 训练判别器\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            real_logits = discriminator(real_images)\n",
    "            fake_logits = discriminator(generated_images)\n",
    "            \n",
    "            real_loss = cross_entropy(real_labels, real_logits)\n",
    "            fake_loss = cross_entropy(fake_labels, fake_logits)\n",
    "            total_discriminator_loss = real_loss + fake_loss\n",
    "        \n",
    "        gradients_discriminator = disc_tape.gradient(total_discriminator_loss, discriminator.trainable_variables)\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_discriminator, discriminator.trainable_variables))\n",
    "        \n",
    "        # 训练生成器\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            generated_images = generator(noise)\n",
    "            fake_logits = discriminator(generated_images)\n",
    "            generator_loss = cross_entropy(real_labels, fake_logits)\n",
    "        \n",
    "        gradients_generator = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(gradients_generator, generator.trainable_variables))\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Generator Loss: {generator_loss}, Discriminator Loss: {total_discriminator_loss}')\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        generate_and_save_images(generator, epoch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Gnet():\n",
    "    net = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm1d(784),\n",
    "            torch.nn.Unflatten(1, (28, 28, 1))\n",
    "        )\n",
    "    \n",
    "    return net\n",
    "\n",
    "def Dnet():\n",
    "    net = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "# 生成并保存生成器生成的图像。\n",
    "def generate_and_save_images(generator, epoch, examples=10):\n",
    "    noise = np.random.normal(0, 1, (examples, 100))\n",
    "    generated_images = generator(torch.from_numpy(noise).float())\n",
    "    generated_images = 0.5 * generated_images + 0.5  # 将图像归一化到[0, 1]范围\n",
    "\n",
    "    plt.figure(figsize=(10, 1))\n",
    "    for i in range(examples):\n",
    "        plt.subplot(1, examples, i + 1)\n",
    "        plt.imshow(generated_images[i, ...].detach().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(f'gan_generated_image_epochaa_{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "g_net = Gnet()\n",
    "d_net = Dnet()\n",
    "\n",
    "g_loss = nn.BCELoss()\n",
    "d_loss = nn.BCELoss()\n",
    "\n",
    "g_optimizer = torch.optim.Adam(g_net.parameters(), lr=0.0002)\n",
    "d_optimizer = torch.optim.Adam(d_net.parameters(), lr=0.0002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.MNIST('./data', \n",
    "                      train=True, \n",
    "                      download=True, \n",
    "                      transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                        ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (train_images, _) in enumerate(train_loader):\n",
    "        # 使用生成器生成假图像\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        g_fake = g_net(torch.from_numpy(noise).float())\n",
    "\n",
    "        # 训练判别器\n",
    "        d_optimizer.zero_grad()\n",
    "        d_real = d_net(train_images)\n",
    "        d_fake = d_net(g_fake)\n",
    "\n",
    "        d_real_loss = d_loss(d_real, torch.ones_like(d_real))\n",
    "        d_fake_loss = d_loss(d_fake, torch.zeros_like(d_fake))\n",
    "        d_loss_all = d_real_loss + d_fake_loss\n",
    "        d_loss_all.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # 训练生成器\n",
    "        g_optimizer.zero_grad()\n",
    "        g_fake = g_net(torch.from_numpy(noise).float())\n",
    "        d_fake = d_net(g_fake)\n",
    "        g_loss_all = g_loss(d_fake, torch.ones_like(d_fake))\n",
    "        g_loss_all.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    generate_and_save_images(g_net, epoch, examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/10] [Batch 600/937] [D loss: 0.5478272438049316] [G loss: 1.5024466514587402]\n",
      "[Epoch 6/10] [Batch 700/937] [D loss: 0.5461592674255371] [G loss: 1.8972598314285278]\n",
      "[Epoch 6/10] [Batch 800/937] [D loss: 0.6142711639404297] [G loss: 1.1090264320373535]\n",
      "[Epoch 6/10] [Batch 900/937] [D loss: 0.42470836639404297] [G loss: 2.109711170196533]\n",
      "[Epoch 7/10] [Batch 0/937] [D loss: 0.6612293720245361] [G loss: 2.0073652267456055]\n",
      "[Epoch 7/10] [Batch 100/937] [D loss: 0.44085943698883057] [G loss: 1.4523869752883911]\n",
      "[Epoch 7/10] [Batch 200/937] [D loss: 0.445727676153183] [G loss: 1.2493127584457397]\n",
      "[Epoch 7/10] [Batch 300/937] [D loss: 0.770003080368042] [G loss: 1.079391360282898]\n",
      "[Epoch 7/10] [Batch 400/937] [D loss: 0.6184177398681641] [G loss: 1.5768896341323853]\n",
      "[Epoch 7/10] [Batch 500/937] [D loss: 0.5827301144599915] [G loss: 1.5450780391693115]\n",
      "[Epoch 7/10] [Batch 600/937] [D loss: 0.37065911293029785] [G loss: 1.642089605331421]\n",
      "[Epoch 7/10] [Batch 700/937] [D loss: 0.6298384666442871] [G loss: 1.7990976572036743]\n",
      "[Epoch 7/10] [Batch 800/937] [D loss: 0.6260653734207153] [G loss: 1.5565638542175293]\n",
      "[Epoch 7/10] [Batch 900/937] [D loss: 0.4640618562698364] [G loss: 1.7005095481872559]\n",
      "[Epoch 8/10] [Batch 0/937] [D loss: 0.5217878222465515] [G loss: 2.022294521331787]\n",
      "[Epoch 8/10] [Batch 100/937] [D loss: 0.40752631425857544] [G loss: 1.7115716934204102]\n",
      "[Epoch 8/10] [Batch 200/937] [D loss: 0.6470761895179749] [G loss: 0.984158456325531]\n",
      "[Epoch 8/10] [Batch 300/937] [D loss: 0.5399479866027832] [G loss: 1.4340711832046509]\n",
      "[Epoch 8/10] [Batch 400/937] [D loss: 0.5023764371871948] [G loss: 1.1860045194625854]\n",
      "[Epoch 8/10] [Batch 500/937] [D loss: 0.6415664553642273] [G loss: 1.9113893508911133]\n",
      "[Epoch 8/10] [Batch 600/937] [D loss: 0.5019020438194275] [G loss: 1.3449081182479858]\n",
      "[Epoch 8/10] [Batch 700/937] [D loss: 0.507339358329773] [G loss: 1.3707101345062256]\n",
      "[Epoch 8/10] [Batch 800/937] [D loss: 0.5255190134048462] [G loss: 1.1208157539367676]\n",
      "[Epoch 8/10] [Batch 900/937] [D loss: 0.5288382172584534] [G loss: 2.293968439102173]\n",
      "[Epoch 9/10] [Batch 0/937] [D loss: 0.7580134868621826] [G loss: 1.453368902206421]\n",
      "[Epoch 9/10] [Batch 100/937] [D loss: 0.5496958494186401] [G loss: 1.4133256673812866]\n",
      "[Epoch 9/10] [Batch 200/937] [D loss: 0.4940105378627777] [G loss: 1.1961278915405273]\n",
      "[Epoch 9/10] [Batch 300/937] [D loss: 0.5240762829780579] [G loss: 1.441497564315796]\n",
      "[Epoch 9/10] [Batch 400/937] [D loss: 0.4359230399131775] [G loss: 1.3653076887130737]\n",
      "[Epoch 9/10] [Batch 500/937] [D loss: 0.6241281032562256] [G loss: 1.0761839151382446]\n",
      "[Epoch 9/10] [Batch 600/937] [D loss: 0.5372806191444397] [G loss: 1.1070001125335693]\n",
      "[Epoch 9/10] [Batch 700/937] [D loss: 0.42936772108078003] [G loss: 1.3857351541519165]\n",
      "[Epoch 9/10] [Batch 800/937] [D loss: 0.4473763406276703] [G loss: 1.4398725032806396]\n",
      "[Epoch 9/10] [Batch 900/937] [D loss: 0.8202038407325745] [G loss: 1.1470743417739868]\n"
     ]
    }
   ],
   "source": [
    "## GAN pytorch 实现\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "data = datasets.MNIST('./data', \n",
    "                      train=True, \n",
    "                      download=True, \n",
    "                      transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                        ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data, batch_size=64, drop_last=True)\n",
    "\n",
    "# Generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, image_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, image_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Unflatten(1, (1, 28, 28))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(image_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Hyperparameters\n",
    "z_dim = 100\n",
    "image_dim = 28 * 28\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "num_epochs = 10\n",
    "sample_interval = 1\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator(z_dim, image_dim)\n",
    "discriminator = Discriminator(image_dim)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(batch_size, 1)\n",
    "        fake = torch.zeros(batch_size, 1)\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size, z_dim)\n",
    "        gen_images = generator(z)\n",
    "        g_loss = criterion(discriminator(gen_images), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = criterion(discriminator(images), valid)\n",
    "        fake_loss = criterion(discriminator(gen_images.detach()), fake)\n",
    "        d_loss = 0.5 * (real_loss + fake_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(train_loader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
    "\n",
    "        if epoch % sample_interval == 0:\n",
    "            save_image(gen_images.data[:25], f\"images/{epoch}.png\", nrow=5, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用imageio生成gif动图\n",
    "\n",
    "import imageio.v3 as iio\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('./gan_generated_image_epoch_{}.png'.format(epoch_no))\n",
    "\n",
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "images = pathlib.Path('./images').glob('*.png')\n",
    "sorted_images = sorted(images)\n",
    "images = np.stack([iio.imread(image) for image in sorted_images], axis=0)\n",
    "iio.imwrite(anim_file, images, fps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用imageio生成视频\n",
    "\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "\n",
    "# read the video (it fits into memory)\n",
    "# Note: this will open the image twice. Check the docs (advanced usage) if\n",
    "# this is an issue for your use-case\n",
    "metadata = iio.immeta(\"imageio:cockatoo.mp4\", exclude_applied=False)\n",
    "frames = iio.imread(\"imageio:cockatoo.mp4\", index=None)\n",
    "\n",
    "# manually convert the video\n",
    "# gray_frames = np.dot(frames, [0.2989, 0.5870, 0.1140])\n",
    "# gray_frames = np.round(gray_frames).astype(np.uint8)\n",
    "\n",
    "images = pathlib.Path('./images').glob('*.png')\n",
    "sorted_images = sorted(images)\n",
    "images = np.stack([iio.imread(image) for image in sorted_images], axis=0)\n",
    "\n",
    "\n",
    "# write the video\n",
    "iio.imwrite(\"cockatoo_gray.mp4\", images, fps=metadata[\"fps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6931, 0.6931])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.array([[0.1, 0.2, 0.3, 0.4], [0.3, 0.2, 0.4, 0.1]])\n",
    "out = np.array([[0.1, 0.1], [0.4, 0.4]])\n",
    "out = torch.from_numpy(out).float()\n",
    "\n",
    "cross_entropy_loss(out, torch.zeros(out.size(0), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.1/(0.1+0.1)) * 1/2 - np.log(0.1/(0.1+0.1)) * 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6931, 0.6931])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = np.array([[0.1, 0.1], [0.4, 0.4]])\n",
    "input2 = np.array([0, 0])\n",
    "\n",
    "cross_entropy_loss(torch.from_numpy(input1).float(), torch.from_numpy(input2).long())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
